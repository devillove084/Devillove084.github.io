{"posts":[{"title":"现代 C++ 分享（1）—— 生命周期、所有权和资源管理","text":"这是整个现代 C++ 分享系列第一篇，关于生命周期、所有权和资源管理。主题包括但不限于指针、智能指针、引用、类型系统、移动语义以及完美转发和引用折叠相关的主题。 C++ 在演进过程中逐渐增强和扩展了对类型处理的能力： C++11 中引入右值引用，通过重新定义值类别对表达式进行分类，右值引用能表达移动语义，解决了 C++11 之前产生的中间临时对象需要多次拷贝的问题； C++11 中引入 auto 关键字，对初始化变量进行推导，并且引入 decltype 关键字，通过已有对象、变量获得类型； C++17 引入 optional 类型表达对象是否存在，并且引入 variant 作为类型安全的 union，类型表达更灵活。 C++20 中引入 concept 特性对类型在编译期做约束，增强类型的表达和检查能力。 在 C++ 中，容器和指针抽象后想要被正确且高效的使用，在工程中通常需要封装一组数据及函数来访问和操作。举例来说，指针是通用和有效抽象的机器地址，但正确使用指针来表示资源的所有权是非常困难的，因此标准库提供了智能指针类管理资源和生命周期。指针的更泛化的概念是，任何允许我们引用对象并根据其类型访问。 指针和引用指针是从 C 语言中延续下来的概念，而引用是在指针基础上结合资源管理进一步在编译器层做的管理手段，其本质在汇编层面并无区别。但是在使用时，需要注意以下几点： 指针是一个变量，它保存了另一个变量的内存地址；引用是另一个变量的别名，与原变量共享内存地址； 指针可以被重新赋值，指向不同的变量；引用在初始化后不能更改，始终指向同一个变量； 指针可以为 nullptr，表示不指向任何变量；引用必须绑定到一个变量，不能为 nullptr； 指针需要对其进行解引用以获取或修改其指向的变量的值；引用可以直接使用，无需解引用。 1234567891011121314151617181920212223#include &lt;iostream&gt;int main() { int a = 10; int b = 20; // 指针 int *p = &amp;a; std::cout &lt;&lt; &quot;Pointer value: &quot; &lt;&lt; *p &lt;&lt; std::endl; // 输出：Pointer value: 10 std::cout &lt;&lt; &quot;Address of value: &quot; &lt;&lt; p &lt;&lt; std::endl; // a的地址 std::cout &lt;&lt; &quot;Address of p: &quot; &lt;&lt; &amp;p &lt;&lt; std::endl; // p的地址 p = &amp;b; std::cout &lt;&lt; &quot;Pointer value: &quot; &lt;&lt; *p &lt;&lt; std::endl; // 输出：Pointer value: 20 // 引用 int &amp;r = a; std::cout &lt;&lt; &quot;Reference value: &quot; &lt;&lt; r &lt;&lt; std::endl; // 输出：Reference value: 10 std::cout &lt;&lt; &quot;Address of a: &quot; &lt;&lt; &amp;a &lt;&lt; std::endl; std::cout &lt;&lt; &quot;Address of r: &quot; &lt;&lt; &amp;r &lt;&lt; std::endl; // r = &amp;b; // 错误：引用不能被重新绑定 int &amp;r2 = b; r = r2; // 将 b 的值赋给 a，r 仍然引用 a std::cout &lt;&lt; &quot;Reference value: &quot; &lt;&lt; r &lt;&lt; std::endl; // 输出：Reference value: 20 return 0;} 引用是 C++ 编译器的约定，那和指针到底有什么区别？ 答：本质上没有区别 堆栈变量生命周期管理在 C++ 中创建变量一般有两种形式： 12A a;A a = new A(); // delete a; 1、静态建立类对象：编译器为对象在栈空间中分配内存，是通过直接计算 A 的空间，移动栈顶指针，挪出适当的空间，然后在这片内存空间上直接调用构造函数形成一个栈对象，在局部作用域退出时，自动调用类的析构函数； 2、动态建立类对象，使用 new 运算符将对象建立在堆空间。先在堆内存中搜索合适的内存并进行分配，再是调用构造函数构造对象，初始化堆内存，生命周期需要手动管理（delete）。 RAIIRAII 是 Resource Acquisition Is Initialization 的简称，其翻译过来就是“资源获取即初始化”，即在构造函数中申请分配资源，在析构函数中释放资源，它是 C++ 语言中的一种管理资源、避免泄漏的良好的设计方法。 C++ 语言的机制保证了，当创建一个类对象时，会自动调用构造函数，当对象超出作用域时会自动调用析构函数。RAII 正是利用这种机制，利用类来管理资源，将资源与类对象的生命周期绑定，即在对象创建时获取对应的资源，在对象生命周期内控制对资源的访问，使之始终保持有效，最后在对象析构时，释放所获取的资源。 12345678std::mutex mut;int write(std::string content) { mut.lock(); // critical area below (might throw exception) // Writing content to a file descriptor... // Critical areas above mut.unlock();} 上述展示了一个写函数，而在多线程并行调用下，内部可能共用的文件描述符必须用一个互斥锁保护，否则不同线程的字符串会混在一起。这段代码看起来没有问题，但是如果当写线程抛出了异常，调用栈会被直接释放，unlock 方法永远不会执行，造成死锁，其他的线程再也拿不到资源。 1234567std::mutex mut;int write(std::string content) { std::lock_guard&lt;std::mutex&gt; lock(mut); // critical area below (might throw exception) // Writing content to a file descriptor... // Critical areas above} lock_guard 保证在函数返回之后或者异常后释放互斥锁，因此无需担心异常情况下手动释放锁的问题。而 lock_guard 的实现，就是使用了“资源在构造函数中定义，在析构中释放的原则”。 123456789101112template &lt;typename T&gt;class lock_guard { public: explicit lock_guard(T &amp;mutex) : _mutex(mutex) { _mutex.lock(); } ~lock_guard() { _mutex.unlock(); } private: T _mutex;}; lock_guard 在构造函数中锁住了引用传入的资源（mutex），并且在析构函数中释放锁。其异常安全的保障就是析构函数一定会在对象归属的 scope 退出时自动被调用。 拷贝赋值&amp;构造拷贝构造函数是一种特殊构造函数，具有单个形参，该形参（常用 const 修饰）是对该类类型的引用。 拷贝赋值函数，也叫赋值操作符重载，因为赋值必须作为类成员，那么它的第一个操作数隐式绑定到 this 指针，赋值操作符接受单个形参，且该形参是同一类类型的对象。右操作数一般作为 const 引用传递。 问：为啥拷贝构造函数的形参必须是引用？ 1234567891011121314151617class Person { public: Person() {} // 默认构造函数 ~Person() {} // 析构函数 Person(const Person&amp; p) { // 拷贝构造函数 cout &lt;&lt; &quot;Copy Constructor&quot; &lt;&lt; endl; } // Persion(const Person&amp; p) = delete; Person&amp; operator=(const Person&amp; p) { // 拷贝赋值函数 cout &lt;&lt; &quot;Assign&quot; &lt;&lt; endl; return *this; } // Person&amp; operator=(const Person&amp; p) = delete; private: int age; string name;}; 拷贝构造函数和赋值运算符的行为比较相似，都是将一个对象的值复制给另一个对象，但是其结果却有些不同。拷贝构造函数使用传入对象的值生成一个新的对象的实例，而赋值运算符是将对象的值复制给一个已经存在的实例。具体来说，拷贝构造函数是构造函数，其功能就是创建一个新的对象实例；赋值运算符是执行某种运算，将一个对象的值复制给另一个对象（已经存在的）。 调用拷贝构造函数主要有以下场景： 对象作为函数的参数，以值传递的方式传给函数； 对象作为函数的返回值，以值的方式从函数返回； 使用一个对象给另一个对象初始化。 深拷贝&amp;浅拷贝 拷贝构造函数和赋值函数并非每个对象都会使用，另外如果不主动编写的话，编译器将以“位拷贝”的方式自动生成缺省的函数。在类的设计当中，“位拷贝”是应当防止的，可以通过“= delete”删除拷贝构造和拷贝复制函数。倘若类中含有指针变量, 并且这两个指针指向重叠的位置，那么这两个缺省的函数就会发生错误。 深拷贝和浅拷贝区分主要是针对类中的指针成员变量，因为对于指针只是简单的值复制并不能分割开两个对象的关联，任何一个对象对该指针的操作都会影响到另一个对象。这时候就需要提供自定义的深拷贝的拷贝构造函数，消除这种影响。通常的原则是： 指针成员应该提供自定义的拷贝构造函数； 在提供拷贝构造函数的同时实现自定义的赋值运算符。 对于拷贝构造函数的实现要确保以下几点： 对于值类型的成员进行值复制； 对于指针和动态分配的空间，在拷贝中应重新分配分配； 对于基类，要调用基类合适的拷贝方法，完成基类的拷贝。 移动赋值&amp;构造（见下文移动语义） 智能指针标准库中指针在经过多年发展后，不仅有耳熟能详的 share_ptr 和 unique_ptr 还多了一些其他的类型，为了对比，我这里也把普通指针和引用放在一起： T*: 内置指针类型，指向类型 T 的对象，或者指向类型 T 的连续内存空间序列； T&amp;：内置引用类型，引用类型 T 的对象（为别名），是一个隐式解引用的指针； unique_ptr：拥有 T 的所有权，指向 T 的独占指针，在离开作用域时，unique_ptr 的析构会销毁其指向的对象； shared_ptr：指向类型 T 对象的共享指针，所有权在所有指向类型 T 对象的 shared_ptr 之间共享，最后一个共享 T 对象的 shared_ptr 离开最后的作用域时负责析构销毁 T 对象； weak_ptr：指向 shared_ptr 拥有的对象，但是不引用计数，需要用 weak 访问对象时，需要提升为 shared_ptr 才可以； span：指向连续序列的 T 元素的指针，为 std::vector 等容器的“视图”； string_view：指向字符串子串的视图； X_iterator: 来自 C 容器的对象序列，“X”代表具体的迭代器类型（map、set…）。 unique_ptrC++ 智能指针详解（一）——unique_ptr shared_ptrC++ 智能指针详解（二）——shared_ptr 与 weak_ptr 值类型在 C++11 之前，很多 C++ 程序里存在大量的临时对象，又称无名对象。主要出现在如下场景： 函数的返回值 用户自定义类型经过一些计算后产生的临时对象 值传递的形参 C++11 之后，左值和右值分为了三个具体的子值类型，和两个混合类型，这里清晰起见，不对泛左值和右值展开。 左值具有以下特征： 可通过取地址运算符获取其地址； 可修改； 可用作内建赋值和内建符合赋值运算符的左操作数； 可以用来初始化左值引用。 举例： 12345678910111213int a = 1; // a是左值T&amp; f(); // 左值f();//左值++a;//左值--a;//左值int b = a;//a和b都是左值struct S* ptr = &amp;obj; // ptr为左值arr[1] = 2; // 左值int *p = &amp;a; // p为左值*p = 10; // *p为左值class MyClass{};MyClass c; // c为左值&quot;abc&quot; // 左值 将亡值可以理解为通过“盗取”其他变量内存空间的方式获取到的值。在确保其他变量不再被使用、或即将被销毁时，通过“盗取”的方式可以避免内存空间的释放和分配，能够延长变量值的生命期。 将亡值只能通过两种方式来获得，这两种方式都涉及到将一个左值赋给(转化为)一个右值引用： 返回右值引用的函数的调用表达式，static_cast&lt;T&amp;&amp;&gt;(T); 转换为右值引用的转换函数的调用表达式，std::move(t)。 12345std::string fun() { std::string str = &quot;test&quot;; return str;}std::string s = fun(); C++11 之前，s = fun()会调用拷贝构造函数，会将整个 str 复制一份，然后再把 str 销毁。str 比较大则会造成巨大开销。一旦 str 被 s 复制后，将被销毁，无法获取和修改。 C++11 后，引入了 move 语义，编译器会将这部分优化成 move 操作，str 会被进行隐式右值转换，等价于 static_caststd::string&amp;&amp;(str)，进而此处的 s 会将 func 局部返回的值进行移动。 纯右值本身就是纯粹的字面值，如 3，false，12.13，或者求值结果相当于字面值或是一个不具名的临时对象。 具体来说： 纯右值不具有多态：它所标识的对象的动态类型始终是该表达式的类型； 纯右值不能具有不完整类型； 纯右值不能具有抽象类类型或它的数组类型。 左值引用和右值引用12345int a = 1;int&amp; b = a; // before c++11// int&amp;&amp; b = a; // error 不能引用左值int&amp;&amp; b = std::move(a); // c++11 左值引用使用“&amp;”标记，右值引用使用“&amp;&amp;”标记。具体来说，在 C++11 之前的引用，都是左值引用，而： 在语句执行完毕之后被销毁的临时对象； std::move()后的非 const 对象 考虑下列代码，应该使用哪个 foo 函数的重载版本： 12345void foo(int&amp;); // 1void foo(int&amp;&amp;); // 2int&amp;&amp; value = 42;foo(value); 答案是使用“1”的函数。虽然这里的变量定义的是右值引用类型，然后 foo(value)中的表达式 value 确是一个左值，而不是由定义 value 时的类型来决定值类型。简单来说，如果表达式能取地址，则为左值表达式，否则为右值表达式。 根据引用和常量性质进行组合，有几种情况： 左值引用 Value&amp;，只能绑定左值表达式，如 1 中形参； 右值引用 Value&amp;&amp;，只能绑定右值表达式，如 2 中形参； 左值常引用 const Value&amp;，可以绑定左、右值表达式，但是后续无法修改值； 右值常引用 const Value&amp;&amp;，只能绑定常量右值表达式，实际中不使用。 问：如何将上述代码中 value 以右值引用的形式传递给 foo，从而调用“2”的函数，两个方法：一是直接 foo(42)，二是通过 foo(static_cast&lt;int&amp;&amp;&gt;(value))。 编译器会匹配为右值引用。 让编译器将对象匹配为右值引用，是移动语义的基础！！！ 移动语义先来说明为什么需要移动语义： case1： 1234567891011class Stuff { public: Stuff(const std::string &amp;s) : str{s} {}; private: std::string str;};std::vector&lt;Stuff&gt; stuff;Stuff tmp{&quot;hello&quot;};stuff.push_back(tmp);stuff.push_back(tmp); 这是一个较为常见的开发 case，创建了一个容器 std::vector 以及自定义类 Stuff，并且添加到容器中两次，注意我们这里并没有对 Stuff 类自定义拷贝构造和拷贝赋值，使用编译器默认实现。tmp 添加到容器中两次，每次添加时都会发生一次拷贝操作，最终内存结构可能是： tmp 对象在添加到容器中两次后，生命周期随之结束。 case2： 123456789101112std::string process1(const std::string&amp; str) { return process2(str);}std::string process2(const std::string&amp; str) { return process3(str);}std::string process3(const std::string&amp; str) { return process4(str);}// ... 回到 case1，现在修改容器的操作为下面的代码： 1234std::vector&lt;Stuff&gt; stuff;Stuff tmp{ &quot;hello&quot; };stuff.push_back(tmp); stuff.push_back(std::move(tmp); 现在可以明确，移动操作执行对象数据转移，拷贝操作复制对象数据。为了能够将拷贝操作与移动操作区分执行，需要不同于拷贝的标记，“&amp;&amp;”应运而生。 在不考虑模板的情况下，针对两种 push_back 函数需要有两种重载实现： 12345678class vector { public: // 上文说到const T&amp; 也是可以绑定右值引用， // 但是因为有限制，只能后续无法修改， // 所以提供也需要提供&amp;&amp;的实现 void push_back(const Stuff&amp; value){} void push_back(Stuff&amp;&amp; value) {}}; 通过传递左值引用或右值引用，根据需要调用不同的 push_back 重载函数。","link":"/2024/03/10/Modern-cpp-1/"},{"title":"多线程共享与伪共享检测","text":"多线程/进程之间使用缓存一致性协议来保证每个包含独立缓存对象的核心在共享使用内存数据时的一致性，缓存一致性协议保证了缓存实体中的任何更新都会对相同位置的其他缓存进行全部更新。MESI协议是最著名的一致性协议，支持现代CPU中缓存回写。通过监控内存事务保持一致性，一致性问题可以得到缓解，但是是有代价的，导致CPU访存空转，浪费系统带宽，两种具有代表性的内存一致性问题是“真共享”和“伪共享”。 “真共享”多线程同时访问相同变量时，为真共享，下列代码简单说明了该问题： 123456let mut sum: u64 = 0;{ // parallel section for i in 0..N { sum += i; // sum is shared between all threads } } 数据竞争是未定义行为，C++下Clang的Thread sanitizer和helgrind可以一定程度检查出数据竞争。而Rust中的数据竞争检测在编译阶段就通过其所有权机制和借用检查器实现，具体的，Rust利用RAII机制在作用域结束时释放对象持有的内存，该内存有且只有一个对象持有，借用检查器是Rust在编译期预防数据竞争的主要手段，确保了在任何时候只有一个线程可以“借用”内存区域。 而在C++中，将sum变量变为原子变量有助于解决真共享发生的数据竞争问题。但是在进行内存顺序的排序、串行化的内存操作之后，会极为影响性能，详细见Perfbook关于多线程Counter的相关设计。 而另外一个解决真共享的方法是使用TLS（Thread Local Storage，TLS）。通过TLS在给定的多线程下，每个线程都可以分配内存来存储该线程内的独占数据，线程之间便可不竞争全局变量。在C++使用thread_local关键字修饰某个变量为线程独占，而在Rust下使用 thread_local 宏可以初始化线程局部变量，然后在线程内部使用该变量的 with 方法获取变量值，或者使用attribute的的#[thread_local]进行标记，或者，可以使用thread_local第三方库，具体例子见下面代码： 123456789101112131415thread_local! { static MACRO_TLS: std::cell::RefCell&lt;Foo&gt; = std::cell::RefCell::new(Foo(0));}#[thread_local]static mut ATTR_TLS: Foo = Foo(0);fn main() { let _ = std::thread::spawn(|| unsafe { MACRO_TLS.with(|f| { println!(&quot;foo: {}&quot;, f.borrow_mut().0); }); }) .join();} 123456789101112131415161718192021222324252627#include &lt;iostream&gt;#include &lt;mutex&gt;#include &lt;string&gt;#include &lt;thread&gt; thread_local unsigned int rage = 1; std::mutex cout_mutex; void increase_rage(const std::string&amp; thread_name){ ++rage; // modifying outside a lock is okay; this is a thread-local variable std::lock_guard&lt;std::mutex&gt; lock(cout_mutex); std::cout &lt;&lt; &quot;Rage counter for &quot; &lt;&lt; thread_name &lt;&lt; &quot;: &quot; &lt;&lt; rage &lt;&lt; '\\n';} int main(){ std::thread a(increase_rage, &quot;a&quot;), b(increase_rage, &quot;b&quot;); { std::lock_guard&lt;std::mutex&gt; lock(cout_mutex); std::cout &lt;&lt; &quot;Rage counter for main: &quot; &lt;&lt; rage &lt;&lt; '\\n'; } a.join(); b.join();} C++的例子来自于cppreference, 当使用该关键字声明时，每个线程都有自己的副本，当通过名称引用时，将使用与当前线程关联的副本。而如果在类的成员上使用thread_local关键字修饰，则在同一个线程内该类的多个成员都会共享该变量，这一点和static关键字一致。 “伪共享”当多个不同的线程修改恰巧位于同一缓存行的不同变量时，称为“伪共享”。下面使用一段代码来说明该问题： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226#define _MULTI_THREADED#define _GNU_SOURCE#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdint.h&gt;#include &lt;unistd.h&gt;#include &lt;sched.h&gt;#include &lt;pthread.h&gt;#include &lt;numa.h&gt;#include &lt;sys/types.h&gt;/* * A thread on each numa node seems to provoke cache misses */#define LOOP_CNT (5 * 1024 * 1024)#if defined(__x86_64__) || defined(__i386__)static __inline__ uint64_t rdtsc() { unsigned hi, lo; __asm__ __volatile__ ( &quot;rdtsc&quot; : &quot;=a&quot;(lo), &quot;=d&quot;(hi)); return ( (uint64_t)lo) | ( ((uint64_t)hi) &lt;&lt; 32);}#elif defined(__aarch64__)static __inline__ uint64_t rdtsc(void){ uint64_t val; /* * According to ARM DDI 0487F.c, from Armv8.0 to Armv8.5 inclusive, the * system counter is at least 56 bits wide; from Armv8.6, the counter * must be 64 bits wide. So the system counter could be less than 64 * bits wide and it is attributed with the flag 'cap_user_time_short' * is true. */ asm volatile(&quot;mrs %0, cntvct_el0&quot; : &quot;=r&quot; (val)); return val;}#endif/* * Create a struct where reader fields share a cacheline with the hot lock field. * Compiling with -DNO_FALSE_SHARING inserts padding to avoid that sharing. */typedef struct _buf { long lock0; long lock1; long reserved1;#if defined(NO_FALSE_SHARING) long pad[5]; // to keep the 'lock*' fields on their own cacheline.#else long pad[1]; // to provoke false sharing.#endif long reader1; long reader2; long reader3; long reader4;} buf __attribute__((aligned (64)));buf buf1;buf buf2;volatile int wait_to_begin = 1;struct thread_data *thread;int max_node_num;int num_threads;char * lock_thd_name = &quot;lock_th&quot;;char * reader_thd_name = &quot;reader_thd&quot;;#define checkResults(string, val) { \\ if (val) { \\ printf(&quot;Failed with %d at %s&quot;, val, string); \\ exit(1); \\ } \\}struct thread_data { pthread_t tid; long tix; long node; char *name;};/* * Bind a thread to the specified numa node.*/void setAffinity(void *parm) { volatile uint64_t rc, j; int node = ((struct thread_data *)parm)-&gt;node; char *func_name = ((struct thread_data *)parm)-&gt;name; numa_run_on_node(node); pthread_setname_np(pthread_self(),func_name);}/* * Thread function to simulate the false sharing. * The &quot;lock&quot; threads will test-n-set the lock field, * while the reader threads will just read the other fields * in the struct. */extern void *read_write_func(void *parm) { int tix = ((struct thread_data *)parm)-&gt;tix; uint64_t start, stop, j; char *thd_name = ((struct thread_data *)parm)-&gt;name; // Pin each thread to a numa node. setAffinity(parm); // Wait for all threads to get created before starting. while(wait_to_begin) ; start = rdtsc(); for(j=0; j&lt;LOOP_CNT; j++) { // Check for lock thread. if (*thd_name == *lock_thd_name) { __sync_lock_test_and_set(&amp;buf1.lock0, 1 ); buf1.lock0 += 1; buf2.lock1 = 1; } else { // Reader threads. switch(tix % max_node_num) { volatile long var; case 0: var = *(volatile uint64_t *)&amp;buf1.reader1; var = *(volatile uint64_t *)&amp;buf2.reader1; break; case 1: var = *(volatile uint64_t *)&amp;buf1.reader2; var = *(volatile uint64_t *)&amp;buf2.reader2; break; case 2: var = *(volatile uint64_t *)&amp;buf1.reader3; var = *(volatile uint64_t *)&amp;buf2.reader3; break; case 3: var = *(volatile uint64_t *)&amp;buf1.reader4; var = *(volatile uint64_t *)&amp;buf2.reader4; break; }; }; } // End of for LOOP_CNT loop // Print out stats // stop = rdtsc(); int cpu = sched_getcpu(); int node = numa_node_of_cpu(cpu); printf(&quot;%ld mticks, %s (thread %d), on node %d (cpu %d).\\n&quot;, (stop-start)/1000000, thd_name, tix, node, cpu); return NULL;}int main ( int argc, char *argv[] ){ int i, n, rc=0; if ( argc != 2 ) /* argc should be 2 for correct execution */ { printf( &quot;usage: %s &lt;n&gt;\\n&quot;, argv[0] ); printf( &quot;where \\&quot;n\\&quot; is the number of threads per node\\n&quot;); exit(1); } if ( numa_available() &lt; 0 ) { printf( &quot;NUMA not available\\n&quot; ); exit(1); } int thread_cnt = atoi(argv[1]); max_node_num = numa_max_node(); if ( max_node_num == 0 ) max_node_num = 1; int node_cnt = max_node_num + 1; // Use &quot;thread_cnt&quot; threads per node. num_threads = (max_node_num +1) * thread_cnt; thread = malloc( sizeof(struct thread_data) * num_threads); // Create the first half of threads as lock threads. // Assign each thread a successive round robin node to // be pinned to (later after it gets created.) // for (i=0; i&lt;=(num_threads/2 - 1); i++) { thread[i].tix = i; thread[i].node = i%node_cnt; thread[i].name = lock_thd_name; rc = pthread_create(&amp;thread[i].tid, NULL, read_write_func, &amp;thread[i]); checkResults(&quot;pthread_create()\\n&quot;, rc); usleep(500); } // Create the second half of threads as reader threads. // Assign each thread a successive round robin node to // be pinned to (later after it gets created.) // for (i=((num_threads/2)); i&lt;(num_threads); i++) { thread[i].tix = i; thread[i].node = i%node_cnt; thread[i].name = reader_thd_name; rc = pthread_create(&amp;thread[i].tid, NULL, read_write_func, &amp;thread[i]); checkResults(&quot;pthread_create()\\n&quot;, rc); usleep(500); } // Sync to let threads start together usleep(500); wait_to_begin = 0; for (i=0; i &lt;num_threads; i++) { rc = pthread_join(thread[i].tid, NULL); checkResults(&quot;pthread_join()\\n&quot;, rc); } return 0;} 这段代码是一个多线程的C代码。具体地，通过创建不同的线程并将它们绑定到特定的NUMA节点，伪造伪共享的效果： NUMA将每个线程绑定到特定的NUMA节点，确保线程在特定物理内存位置上运行； 高精度计时使用rdtsc指令测量代码段的执行时间； 伪共享和缓存行对齐结构体buf中成员可能会因为缓存行对齐而共享相同的缓存行。 这里有两种编译模式： 默认模式下只有一个长整型的填充，用于触发伪共享； 另一模式通过定义 NO_FALSE_SHARING 预处理宏，增加额外的填充以避免伪共享。 下面是一些代码的详细解释和补充说明，可以按需跳过： 结构体 buf 的设计：这个结构体有两个锁变量 lock0 和 lock1，以及四个变量 reader1 到 reader4。根据编译选项，这些变量可能位于同一缓存行（为了故意制造伪共享），或者通过插入填充以分开到不同的缓存行（为了避免伪共享）。 线程功能 read_write_func：每个线程都会执行这个函数。如果是锁线程（通过名称判断），它会连续设置并增加锁变量；如果是读取线程，它则会读取指定的读变量。这样设计是为了在锁和读取之间制造大量的内存访问和潜在的竞争。 主函数：首先检查 NUMA 是否可用，然后解析命令行参数来确定每个 NUMA 节点应创建多少线程。之后，为每个线程分配一个结构体 thread_data，用于存储线程的元数据，如线程 ID、所属 NUMA 节点和线程名称。然后创建线程，先是锁线程后是读取线程，每个线程都通过 pthread_create 调用启动。 下面介绍perf工具如何检查伪共享，以及如何解读结果。Linux perf工具和Intel VTune Profiler都支持检测伪共享。这里仅对perf工具进行展开，perf c2c会匹配不同线程的内存保存和和加载地址，并查看是否有在被修改的缓存行的命中。这里先对上述C代码进行编译和运行，并在同时收集perf data： 12345clang -g false_sharing_example.c -pthread -lnuma -o false_sharing./false_sharing.exe &lt;number of threads per node&gt;sudo perf c2c record -F 60000 -a -u --ldlat 50 sleep 3 结果： 结果1：HITM代表的是在修改后的cacheline中命中的负载，这是伪共享发生的关键指标。 Remote HITM是跨NUMA节点，是最贵的操作； 结果2：第二个结果是个排序的热度，按cacheline的远程HITM或本地HITM进行排序，Rmt LLC Load Hitm标记了跨NUMA节点； 结果3：访问cache line的平均延迟、CPU时钟周期、线程pid、函数之类的信息，具体的： Shared Data Cache Line Table：每一行代表一个缓存行，列出内存地址、所属NUMA节点、页面访问计数（PA cnt）、命中次数（Hitm）、以及其他的一些命中和失效统计数据。可以看出缓存行地址分别有超过50,000次的总访问（Total records），它们在本地节点（LclHitm）和远程节点（RmtHitm）上的命中次数，这可以显示出在不同节点间的数据共享模式。 Shared Cache Line Distribution Pareto：展示缓存行命中的分布情况。可以看到远程命中（RmtHitm）和本地命中（LclHitm）的百分比，这是衡量NUMA节点之间内存访问效率的重要指标。比如，对于第一行（#0）的缓存行，有大约30%的访问是本地命中，也有相似的百分比是远程命中，有相当比例的内存访问需要跨越 NUMA 节点，这通常会导致更高的延迟。 Code address, cycles, and symbols：列出了代码地址与其对应的 CPU 周期数，这有助于识别哪些函数可能对缓存行产生影响，并估计它们的影响大小。例如，对于不同的代码地址，有不同的本地和远程命中次数（lcl hitm 和 rmt hitm），可以识别出哪些代码路径可能导致不必要的远程内存访问。","link":"/2024/04/19/False-share/"},{"title":"DuckDB-源码分析（1）背景与应用","text":"2019年，CWI发表了一篇关于DuckDB的论文：《DuckDB: an Embeddable Analytical Database》，旨在OLAP领域构建一个嵌入式的数据库，解决单点交互式数据分析的问题，并给边缘计算提供除SQLite之外的更优选择。在论文中，作者们总结DuckDB为在一个进程内的SQL OLAP DBMS，这句话至少有两个解读点： DuckDB的工作方式应该和SQLite一致，即在进程内部运行，并不需要类似MySQL或者PG的等单独起一个数据库服务； 作为AP系统，可以支撑一定复杂的数据分析和查询任务。 SQLite是在全球运行最多的关系型数据库管理系统，每个浏览器和操作系统以及各种嵌入式设备都能找到该数据库使用的痕迹。但是SQLite更多为TP任务服务，很难利用向量化、内存加速来提高数据分析的速度。所以DuckDB弥补了SQLite这方面的空白。 DuckDB 支持多种数据格式： CSV: 批量加载 CSV 文件并自动映射列内容； DataFrames: DuckDB 可以直接处理同一个 Python 进程中的 DataFrame 内存内容；JSON: DuckDB可以直接将JSON转换为关系型表格。也提供 JSON 数据类型； Parquet: DuckDB 可以查询 Parquet 文件及其架构元数据。查询中使用的谓词会下推到 Parquet 存储层进行计算，以减少加载的数据量。Parquet 是数据湖泊理想的列式格式，可用于读写数据； Apache Arrow: DuckDB 可以通过ADBC直接访问 Apache Arrow 列式数据，无需复制和转换数据； 云存储: DuckDB 可以访问云存储桶（例如 S3 或 GCP）中的数据，减少传输和复制基础设施，并允许廉价处理大量数据。 DuckDB官方提供了一个简单的WASM版本的在线环境：https://shell.duckdb.org/，可以直接在内部执行SQL，简单如下所示： 1234567891011121314151617181920212223242526272829duckdb&gt; SELECT count(*) FROM 'https://shell.duckdb.org/data/tpch/0_01/parquet/lineitem.parquet';┌──────────────┐│ count_star() │╞══════════════╡│ 60175 │└──────────────┘duckdb&gt; SELECT count(*) FROM 'https://shell.duckdb.org/data/tpch/0_01/parquet/customer.parquet';┌──────────────┐│ count_star() │╞══════════════╡│ 1500 │└──────────────┘duckdb&gt; SELECT * FROM 'https://shell.duckdb.org/data/tpch/0_01/parquet/orders.parquet' LIMIT 10;┌────────────┬───────────┬───────────────┬──────────────┬─────────────┬─────────────────┬─────────────────┬────────────────┬───────────────────────────────────────────────────────────────────────────┐│ o_orderkey ┆ o_custkey ┆ o_orderstatus ┆ o_totalprice ┆ o_orderdate ┆ o_orderpriority ┆ o_clerk ┆ o_shippriority ┆ o_comment │╞════════════╪═══════════╪═══════════════╪══════════════╪═════════════╪═════════════════╪═════════════════╪════════════════╪═══════════════════════════════════════════════════════════════════════════╡│ 1 ┆ 370 ┆ O ┆ 172799.49 ┆ 1996-01-02 ┆ 5-LOW ┆ Clerk#000000951 ┆ 0 ┆ nstructions sleep furiously among ││ 2 ┆ 781 ┆ O ┆ 38426.09 ┆ 1996-12-01 ┆ 1-URGENT ┆ Clerk#000000880 ┆ 0 ┆ foxes. pending accounts at the pending, silent asymptot ││ 3 ┆ 1234 ┆ F ┆ 205654.3 ┆ 1993-10-14 ┆ 5-LOW ┆ Clerk#000000955 ┆ 0 ┆ sly final accounts boost. carefully regular ideas cajole carefully. depos ││ 4 ┆ 1369 ┆ O ┆ 56000.91 ┆ 1995-10-11 ┆ 5-LOW ┆ Clerk#000000124 ┆ 0 ┆ sits. slyly regular warthogs cajole. regular, regular theodolites acro ││ 5 ┆ 445 ┆ F ┆ 105367.67 ┆ 1994-07-30 ┆ 5-LOW ┆ Clerk#000000925 ┆ 0 ┆ quickly. bold deposits sleep slyly. packages use slyly ││ 6 ┆ 557 ┆ F ┆ 45523.1 ┆ 1992-02-21 ┆ 4-NOT SPECIFIED ┆ Clerk#000000058 ┆ 0 ┆ ggle. special, final requests are against the furiously specia ││ 7 ┆ 392 ┆ O ┆ 271885.66 ┆ 1996-01-10 ┆ 2-HIGH ┆ Clerk#000000470 ┆ 0 ┆ ly special requests ││ 32 ┆ 1301 ┆ O ┆ 198665.57 ┆ 1995-07-16 ┆ 2-HIGH ┆ Clerk#000000616 ┆ 0 ┆ ise blithely bold, regular requests. quickly unusual dep ││ 33 ┆ 670 ┆ F ┆ 146567.24 ┆ 1993-10-27 ┆ 3-MEDIUM ┆ Clerk#000000409 ┆ 0 ┆ uriously. furiously final request ││ 34 ┆ 611 ┆ O ┆ 73315.48 ┆ 1998-07-21 ┆ 3-MEDIUM ┆ Clerk#000000223 ┆ 0 ┆ ly final packages. fluffily final deposits wake blithely ideas. spe │└────────────┴───────────┴───────────────┴──────────────┴─────────────┴─────────────────┴─────────────────┴────────────────┴───────────────────────────────────────────────────────────────────────────┘ 再测试一下语言的API使用，也非常简单，这里以Python为例： 12345678910111213141516171819202122import duckdbcon = duckdb.connect()con.sql(&quot;SELECT * FROM 'orders.parquet' LIMIT 10&quot;).show()con.close()┌────────────┬───────────┬───────────────┬──────────────┬─────────────┬─────────────────┬─────────────────┬────────────────┬───────────────────────────────────────────────────────────────────────────┐│ o_orderkey │ o_custkey │ o_orderstatus │ o_totalprice │ o_orderdate │ o_orderpriority │ o_clerk │ o_shippriority │ o_comment ││ int32 │ int32 │ varchar │ double │ date │ varchar │ varchar │ int32 │ varchar │├────────────┼───────────┼───────────────┼──────────────┼─────────────┼─────────────────┼─────────────────┼────────────────┼───────────────────────────────────────────────────────────────────────────┤│ 1 │ 370 │ O │ 172799.49 │ 1996-01-02 │ 5-LOW │ Clerk#000000951 │ 0 │ nstructions sleep furiously among ││ 2 │ 781 │ O │ 38426.09 │ 1996-12-01 │ 1-URGENT │ Clerk#000000880 │ 0 │ foxes. pending accounts at the pending, silent asymptot ││ 3 │ 1234 │ F │ 205654.3 │ 1993-10-14 │ 5-LOW │ Clerk#000000955 │ 0 │ sly final accounts boost. carefully regular ideas cajole carefully. depos ││ 4 │ 1369 │ O │ 56000.91 │ 1995-10-11 │ 5-LOW │ Clerk#000000124 │ 0 │ sits. slyly regular warthogs cajole. regular, regular theodolites acro ││ 5 │ 445 │ F │ 105367.67 │ 1994-07-30 │ 5-LOW │ Clerk#000000925 │ 0 │ quickly. bold deposits sleep slyly. packages use slyly ││ 6 │ 557 │ F │ 45523.1 │ 1992-02-21 │ 4-NOT SPECIFIED │ Clerk#000000058 │ 0 │ ggle. special, final requests are against the furiously specia ││ 7 │ 392 │ O │ 271885.66 │ 1996-01-10 │ 2-HIGH │ Clerk#000000470 │ 0 │ ly special requests ││ 32 │ 1301 │ O │ 198665.57 │ 1995-07-16 │ 2-HIGH │ Clerk#000000616 │ 0 │ ise blithely bold, regular requests. quickly unusual dep ││ 33 │ 670 │ F │ 146567.24 │ 1993-10-27 │ 3-MEDIUM │ Clerk#000000409 │ 0 │ uriously. furiously final request ││ 34 │ 611 │ O │ 73315.48 │ 1998-07-21 │ 3-MEDIUM │ Clerk#000000223 │ 0 │ ly final packages. fluffily final deposits wake blithely ideas. spe │├────────────┴───────────┴───────────────┴──────────────┴─────────────┴─────────────────┴─────────────────┴────────────────┴───────────────────────────────────────────────────────────────────────────┤│ 10 rows 9 columns │└──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘ DuckDB的实现主要分为几个部分，parser、logical planner、optimizer、physical planner、execution engine和storage engine。 ParserDuckDB的SQL parser直接使用Postgres的libpg_query，可以直接得到一个C结构体表示的parse tree。DuckDB将其转换成自己内部的C++对象，无缝接入。 Logical PlannerDuckDB的Logical planner由binder和plan generator两部分组成，binder将parse tree与schema的信息（列名、类型等）绑定。plan generator将parse tree转换成一棵逻辑查询算子（scan, filter, project等）结构树。经过planning阶段后生成logical plan，DuckDB同时保存所存储数据的统计信息，这些数据在logical plan生成阶段通过不同的expression trees向下传播，用于optimizer阶段优化查询计划。 OptimizerDuckDB实现了RBO和CBO的优化器。Optimizer将前面logical planner生成的logical plan转换成一个等价但执行代价更小的计划。常见的优化方式有predicate pushdown、expression rewriting、join ordering等。 Physical PannerPhysical planner将logical plan转换成physical plan。在生成physical plan过程中，会选择合适的实现。 Execution EngineDuckDB实现了一个向量化执行引擎，execution engine以火山的模式开始执行查询计划的。Query execution以从物理执行计划的root节点拉取chunk data开始。chunk data是结果集中间表或者基表的水平子集，递归的从子节点拉取数据，到scan operator为止。scan operator从persistent tables中读取chunk data。回溯到root节点的chunk是空时则代表该计划已经执行完。 可移植性问题没有选择JIT实现，因为JIT依赖编译组件，比如LLVM。 TransactionDuckDB使用MVCC提供了ACID，DuckDB实现了HyPer的MVCC变体，就地更新数据，并将previous states保存在一个单独的undo buffer，用于并发事务或者中止。 StorageDuckDB使用列式存储，并使用了读优化的数据存储布局。逻辑表水平划分为chunks of columns，这些chunk of columns压缩成physical block。physical block中保存min/max索引，用于在查询时判断该Block是否相关，裁剪block读的大小。也为每个column保留索引，优化列读。 作为新手学习OLAP，DuckDB是一个非常好的开始，相比于Clickhouse或者其他大型AP实现，其抽象和代码都相对清晰和完善，但是因为使用场景有限，面向云上和多核以及分布式下的设计就需要参考其他的数据库，接下来笔者会从不同部分对DuckDB进行展开和详细剖析。","link":"/2024/05/04/DuckDB-1/"},{"title":"数据库事务模型分析（1）—— 计算模型","text":"事务服务的计算模型可以通过多种方法精确创建，和抽象程度有关，而建模数据库事务服务的系统需要遵循一些基本的方法论以及相关实际因素，本系列所作的建模一般分为以下5个步骤： 首先定义数据对象的基础操作，这些操作被认为是原子的，并且独立于其他操作，这一步并没有明确定义什么是数据对象以及需要考虑什么类型数据的基础操作。因此本系列定义两种不同的计算模型：页模型和对象模型； 对事务以及事务执行顺序建模，将其视为在数据对象上基础操作的一个（全/偏）序列； 本系列使用调度或者历史的概念作为对事务执行并发的抽象； 在所有句法正确的调度中，必须从中识别出保证ACID“正确”的调度； 需要“算法”或者“协议”来即时地创建事务正确的调度，当事务提交之后，可以被动态执行； 上述的“页模型”是一个非常简单的模型，可以观察在存储层中，数据页是如何被事务优雅的读写的。接下来可以看到这个模型以一种非常优雅的方式建模了并发控制和事务恢复的实现，并且可以描述非常多（但不是全部）系统实现中的重要语义。“对象模型”是预留给数据库的上层操作，比如访问层或者查询处理层的操作，很容易想到把上层数据应用的业务数据对象考虑在内，可以推导出更复杂的对抽象数据结构ADT的语义，借由ADT来执行下层数据对象的操作。 页模型定义页模型基于一个基本假设： 所有对数据的高层操作都会转化为对数据页的读写操作，并且假设每个页的操作都是不可分的，无论是内存还是在硬盘上。 在用页模型给出事务的一般定义之前，先看一个简化的版本，把事务看作具有全序关系的一组操作步骤，而一般页模型允许偏序关系：一个事务$t$(在页模型中)是形如$r(x)$或者$w(x)$的操作步骤的有限序列，记作： $$t = p_1…p_n$$其中，$n &lt; \\infty$, 对于$1 \\leq i \\leq n$，$x \\in D$，有$p_i \\in {r(x), w(x)}$，这样就从事务执行的细节中抽象出事务执行的读写序列了。 在同一个事务中，操作步骤由$p_i$表示，即事务中第$i$步操作，存在多个事务的情况下，可以给每个事务添加一个唯一的事务id，作为步骤的另外一个下标，$p_{ij}$就代表了第$i$个事务的第$j$步，但是在页模型中为了简化问题，可以简单的从上下文推断出第几步，因此不显式给出步数。只考虑一个事务，可以表示为：$$p_j = r/w(x)$$ 理解为事务第$j$步读/写页数据。实际上，无需把一个事务的所有步骤排成一个严格先后执行的序列，可以放松对事务执行步骤全序的要求，接下来定义事务的偏序：设$A$为任意一个集合，$R \\subseteq A \\times A$，如果对于任意的元素$a, b, c \\in A$，下面三个关系都满足，则称关系$R$是集合$A$上的一个偏序： $(a, a) \\in R$ 自反性 $(a, b) \\in R \\wedge (b,a) \\in R \\Rightarrow a = b$ 反对称性 $(a, b) \\in R \\wedge (b,c) \\in R \\Rightarrow (a,c) \\in R$ 传递性 偏序是全序的一个特例，全序在偏序的定义上又增强了约束，即对于任意两个不同的元素$a, b \\in A$，或者$(a,b) \\in R$或者$(b,a) \\in R$，也就是说对两个不同的数据操作在事务集合中的顺序满足唯一约束。 下面根据偏序定义可以给出在页模型下的事务定义：一个事务$t$是具体有$r(x)$或$w(x)$形式的多个操作步骤的偏序集合，其中$x \\in D$，对同一个页数据的读写操作和写写操作是有序的，正式的，事务可以表示为一个二元组：$$t=(op, &lt;)$$ 其中，$op$是具有$r(x)$或者$w(x)$的有限集合，$x \\in D$且$x&lt; \\subseteq op \\times op$是在$op$集合上的偏序关系，如果${p,q} \\subseteq op$且$p, q$都对同一个页数据项进行访问，且$p,q$是少有一个是写操作，则有$p &lt; q \\wedge q &lt; p$。 根据页事务模型的数学定义可推理出，偏序关系下，不允许同一数据项的读写操作或者写写操作乱序。 对象模型对象模型可以认为是页模型的替代或者推广，实际上，页模型是隐含在对象模型中。对象模型提供了一个表达在任意类型对象上进行的操作框架，而处于提高性能的需要，可能还需要利用被调用操作的语义。实际上，在一个对象及其操作的实现过程中，是需要调用底层对象的操作。 例如在数据库访问层中，比如索引查找，需要调用存储层面向页的操作，类似的调用层次还在业务对象集合中。上图中描述了一个事务，标记为$t_1$，执行了一个SQL的Select语句，从数据库中获取所有名叫“tom”的人员信息，在获取结果后，执行一个SQL语句插入一个新信息。 SQL语句在SQL引擎侧已经被转化为查询处理层的操作。在这个例子中，假设包含两个记录$x$和$y$，查询操作调用存储层的读写页操作。这里假设要读B+树的根节点，并且简单起见，只有两层。叶子节点标记为$l$，其中包含所有符合“tom”的列表，通过主键获取满足条件的记录$x$和$y$，访问每个记录各需要一次页读取，页分别记为$p$和$q$，最后还需要调用一个SQL的Insert语句插入新的信息：首先读取存储层的元数据页，找到有足够空闲的页$p$，读取页$p$，把要插入的记录写入，然后写回该页，最后还要在索引上把新记录的主键加入到B+树上名字叫“tom”的列表中。 上述例子中，实际上是把事务看作一棵树，而被调用的操作作为树节点，为了保证事务树是独立的并且允许严格推理，要求事务树的叶节点必须是页模型的基本读写操作。如果一个给定事务树的叶节点全部或者部分与页读写不对应，唯一能做的就是扩展这棵树把叶子节点全部变成页读写操作。 而这种扩展是动态的，跟踪在执行过程中一个高级事务中的所有低级数据操作，而不是从操作的静态结构生成的一个调用层次图。而跟踪一个事务内部操作的顺序，一种简单的方法就是给所有的叶节点确定一个顺序，和上述图中从左到右的事务顺序一致。所以像页模型一样，也同样要求事务树的所有叶节点保持偏序关系。 现在可以正式给出对象模型事务的定义：一个事务$t$是一棵有限树，节点进行如下标记： 事务标识符来标记根节点； 被调用操作的名称和参数标记内部非叶非根节点； 页模型的读写操作标记叶子节点；在叶子节点上定义了偏序关系“$&lt;$”，使得所有的叶子节点操作$p,q$，其中$p$形如$w(x)$, q形如$r(x) \\wedge w(x)$，或相反，都满足$p &lt; q \\vee q &lt; p$。 对象模型中事务对应的树不一定是平衡的，也就是说从根节点到所有叶子节点的路径不一定是等长的，而为了清晰起见，讨论问题时把属于同样对象操作类型或者接口的操作放在事务树的同层，所以当后续利用对象模型考虑并发执行时，经常放在完全平衡的事务树中。 这种事务树所有叶节点到根节点的路径是等长的，成为分层事务或者多级事务。 在上述的讨论中，有一个问题被忽略了，偏序只在树的叶子节点被提及和定义。内部节点的顺序实际上在叶子节点被约束后已经被隐式定义了。例如，对两个内部节点操作$a$和$b$，如果在叶子节点偏序“&lt;”下，$a$节点下的所有后代叶子节点先于$b$节点下的所有后代叶子节点处理，则称$a$先于$b$，这需要后代叶子节点集合之间有序，否则称$a$和$b$是并发操作。如果想找到中间节点对存储引擎的数据影响，可以检查其子女节点以及更远后代之间的交叉情况，直到叶子节点，其中的偏序关系保证了数据解释的明确性。 最后简要的阐述后续系列如何使用引入的对象模型作为高级并发控制算法的基础来结束本节。当考虑多个事务以并发或者并行的方式执行时，要把所有的事务树组合，形成一个操作的森林，然后检查叶子节点之间的偏序关系，以及隐含推导出来的高层操作顺序。与单层事务不同的是，需要在所有事务树的所有叶子节点集合上来定义偏序关系。而由于内部节点之间的顺序可以由叶子节点的偏序关系推导，可以研究高层节点之间的并发或者并行。而增强事务性能的关键，是高层内部节点操作的语义特性纳入事务调度的考虑范围。","link":"/2024/05/09/Transaction-1/"},{"title":"数据库事务模型分析（2）—— 正确性分析","text":"在本节中，基于上一节的页模型，提出并发执行正确性的概念，并建立多个事务在时间上交叉执行的模型，提出有关并发事务调度的概念。首先要明确的是，事务的执行是高度动态的，完全建模会带来巨大的理解成本，实际上，当事务到来，并发控制需要对该事务做出执行决定，并使能其和系统中正在运行的事务正确同步。其次，需要考虑执行失败而被终止的事务，在正常执行的路径中，包含提交终止。这些操作的处理方式和直觉很不一样。 并发执行的事务之间的数据访问操作存在潜在的冲突，比如“修改后丢失”、“读不一致”、“脏读”等问题，作为事务执行顺序的保证来说，这些异常都是要避免的，要改外部一个执行一致的印象。 为了判断事务执行时，何种情况是期望的，何种情况是应该避免的，调度器需要在线的应用这些规则。首先，本文假定调度中包含了事务结束标志成功或者不成功，具体的，一个事务成功的结束使用$c$表示，即事务在没有被中断的情况下完成了内部所有的数据操作，而失败事务的结束使用$a$表示，一个被终止的事务不应该对底层数据产生任何影响，这由恢复过程保证。 调度和历史设$T={t_1,…,t_n}$是一个有限事务集合，对每一个$t_i \\in T$，都有$t_i=(op_i,&lt;_i)$，其中$op_i$是$t_i$的操作集合，$&lt;_i$表示操作的顺序，$i \\in [1, n]$。$T$中的一个历史$s=(op(s),&lt;_s)$定义如下： $op(s) \\subseteq \\bigcup_{i=1}^{n}op_i \\bigcup_{i=1}^{n}{a_i,c_i}$，并且$\\bigcup_{i=1}^{n}op_i \\subseteq op(s)$，即事务的历史$s$是由事务所有操作的并集和每个事务的终止操作组成； $ \\forall i \\in [1,n], c_i \\in op(s) \\Leftrightarrow a_i \\notin op(s)$，也即每个事务都有结束，成功或者失败，但不能同时存在； $ \\bigcup_{i=1}^{n}&lt;_i \\subseteq &lt;_s$，也即所有事务的顺序都包含在由$s$给出的偏序中； $ \\forall i \\in [1,n], \\forall p \\in op_i, p &lt;_s a_i | p &lt;_s c_i$，也即成功或者失败总是作为事务最后一步出现； 对每一个来自不同事务的一对操作$p,q \\in op(s)$，如果访问同一个数据页并且其中至少一个为写操作，满足$p&lt;_s q|q &lt;_s p$。 因此一个历史，或者满足偏序的事务来说，必须：包含所有事务的所有操作（1），使每个事务都包含唯一的结束符（2），保持每个事务中操作的顺序（3），以结束符作为每个事务的最后一步（4），安排冲突操作的顺序（5）。由于（1）和（2），字面上历史也被称作完整调度。 调度和历史的正确性调度的Herband语义终态可串行性视图可串行性冲突可串行性交叉存取的正确性相关历史背景（选读）本文对调度的Herbrand语义和类FSR、VSR、CSR的介绍大都来自Papadimitriou（1986）和Hadzilacos（1988）。两者不同的是，前者在讨论可串行性时忽略了异常终止的事务，后者则没有忽略。而要考虑异常终止的事务，必须考虑以下定义：事务$t_i \\in trans(s)$的操作$r_i(x) \\in s$。","link":"/2024/05/12/Transaction-2/"}],"tags":[{"name":"cpp2x","slug":"cpp2x","link":"/tags/cpp2x/"},{"name":"Performance","slug":"Performance","link":"/tags/Performance/"},{"name":"DuckDB","slug":"DuckDB","link":"/tags/DuckDB/"},{"name":"transaction","slug":"transaction","link":"/tags/transaction/"}],"categories":[],"pages":[{"title":"about","text":"","link":"/about/index.html"},{"title":"categories","text":"","link":"/categories/index.html"},{"title":"tags","text":"","link":"/tags/index.html"}]}